{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1228ec27-35d2-436b-a4da-e3e5976e3cb5",
   "metadata": {},
   "source": [
    "# Testing the UF\n",
    "\n",
    "## Downloading the 4th layer data from the soil moisture DB (Thingsboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f92a6155-6264-48cf-b0d8-c18dce40e048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is : 20240625 // Week: 26\n",
      "Emergence week of corn : 18 // 8 weeks from now\n",
      "Emergence week of soybean : 20 // 6 weeks from now\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "#  downloading the soil moisture data using the thingsboard API\n",
    "\n",
    "# Set up parameters for the simulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import datetime as dt\n",
    "import statistics as stats\n",
    "import os\n",
    "#*################ Global Parameters ################*#\n",
    "# transmitter info\n",
    "CTRS = ['0554','0556','0557','0558','0629','0630']  # Corn Transmitter IDs\n",
    "CITRS = ['0630','0557']\n",
    "CFTRS = ['0556','0629']\n",
    "CRTRS = ['0554','0558']\n",
    "STRS = ['0111','0112','0113','0114','0115','0116']   # Soybean Transmitter IDs\n",
    "SITRS = ['0112','0114']\n",
    "SFTRS = ['0113','0116']\n",
    "SRTRS = ['0111','0115']\n",
    "\n",
    "CED = pd.Timestamp(2024, 5, 1) # Corn Emergence Date\n",
    "SED = pd.Timestamp(2024, 5, 15) # Soybean Emergence Date\n",
    "\n",
    "CRZMD = 24 # Corn Root Zone Max Depth (in)\n",
    "CRZMDW = 7 # Week of Corn reaches Root Zone Max Depth (at the end of the week)\n",
    "CRZI = 4 # Corn Root Zone Initial Depth (in)\n",
    "CRZIW = 1 # Week of Corn reaches Root Zone Initial Depth\n",
    "\n",
    "SRZMD = 24 # Soybean Root Zone Max Depth (in)\n",
    "SRZMDW = 7 # Week of Soybean reaches Root Zone Max Depth (at the end of the week)\n",
    "SRZI = 4 # Soybean Root Zone Initial Depth (in)\n",
    "SRZIW = 1 # Week of Soybean reaches Root Zone Initial Depth\n",
    "\n",
    "\n",
    "#*################ Mendatory Parameters ################*#\n",
    "\n",
    "\n",
    "def get_periods(CED, SED):\n",
    "    # get today's date as string\n",
    "    from datetime import date\n",
    "    today = date.today().strftime(\"%Y%m%d\")\n",
    "\n",
    "    # Get today's date as datetime\n",
    "    TDY = pd.Timestamp.today()\n",
    "    TWK = TDY.isocalendar().week\n",
    "    print('Today is :', today, '// Week:', TWK)\n",
    "    # Corn Week From Emergence\n",
    "    Cweek = CED.isocalendar().week\n",
    "    CWPE = TWK - Cweek  # Corn Week From Emergence\n",
    "    print('Emergence week of corn :', Cweek, '//',CWPE, 'weeks from now')\n",
    "\n",
    "    # Soybean Week From Emergence\n",
    "    Sweek = SED.isocalendar().week\n",
    "    SWPE = TWK-Sweek  # Soybean Week From Emergence\n",
    "    print('Emergence week of soybean :', Sweek, '//',SWPE, 'weeks from now')\n",
    "\n",
    "    return today, TDY, CWPE, SWPE\n",
    "\n",
    "\n",
    "today, TDY, CWPE, SWPE = get_periods(CED, SED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fcfcc6e-7434-40e4-aaff-679609c87c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server:  https://things.iot.ag.purdue.edu:8080\n",
      "2024-05-01 18:00:00 2024-06-25 06:00:00\n",
      "File Export Done.\n"
     ]
    }
   ],
   "source": [
    "# // this part is download the data from the website for 2 month.\n",
    "import requests\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import datetime\n",
    "import pytz\n",
    "# import config  # I don't know what is this config but this is meaningless DK 2024-06-24\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "deviceList = []\n",
    "\n",
    "# ** set the configuration for the request                                                                                  **\n",
    "config = {\n",
    " 'username' : 'yang2309@purdue.edu', ### Insert your email address used by AgIT Thingsboard system\n",
    " 'password': 'dsya2002',  ### Insert your AgIT thingsboard password\n",
    " 'server' : 'https://things.iot.ag.purdue.edu:8080'\n",
    "}\n",
    "\n",
    "# ** defining the function to get the token for the request and setting the header for the request                          **\n",
    "def getCustomerDevices(custID, textSearch=None):\n",
    "    parameters = {        \n",
    "        'pageSize': 1000,\n",
    "        'page': 0,                \n",
    "    }\n",
    "    att_parms = {\n",
    "        'keys': 'dev_eui'\n",
    "    }\n",
    "    if(textSearch):\n",
    "        parameters.update({'textSearch': textSearch})\n",
    "    responseList = requests.get(f\"{config['server']}/api/customer/{custID}/devices\", headers=TBheaders,params= parameters).json()\n",
    "    #pprint(responseList)\n",
    "    list = []\n",
    "    for dev in responseList['data']:\n",
    "        #pprint(dev)\n",
    "        #print('------------------------------------------------------------------------------------------')\n",
    "        #'id': {'entityType': 'DEVICE', 'id': 'd49153a0-c868-11eb-95d8-09d06ef6a9a5'},\n",
    "        url = f\"{config['server']}/api/plugins/telemetry/DEVICE/{dev['id']['id']}/values/attributes\"\n",
    "        deviceResp = requests.get(url, headers=TBheaders,params= att_parms).json()\n",
    "        #print('------------------------------------------------------------------------------------------')\n",
    "        list.append([dev['id']['id'],dev['name'],deviceResp[0]['value']])\n",
    "    return list\n",
    "        \n",
    "\n",
    "def login(url, username, password):\n",
    "    # Log into ThingsBoard\n",
    "    return requests.post(f\"{url}/api/auth/login\", json={\n",
    "        \"username\": username,\n",
    "        \"password\": password\n",
    "    }).json()['token']\n",
    "\n",
    "def get_keys(device):\n",
    "    return requests.get(f\"{config['server']}/api/plugins/telemetry/DEVICE/{device}/keys/timeseries\",\n",
    "                 headers=TBheaders).json()\n",
    "def get_data_chunk(url, token, device, key, start, stop, limit):\n",
    "    #print([url, device, key, start, stop, limit])\n",
    "    return requests.get(f\"{url}/api/plugins/telemetry/DEVICE/{device}/values/timeseries\",\n",
    "             headers=TBheaders,\n",
    "            params= {\n",
    "                'keys': key,\n",
    "                'startTs': start,\n",
    "                'endTs': stop,\n",
    "                'limit': limit,\n",
    "                'agg': 'NONE'\n",
    "            }).json()\n",
    "\n",
    "def get_data(url, token, device, key, start, stop):\n",
    "    global totalLength\n",
    "    p = pd.DataFrame()\n",
    "    \n",
    "    # You have to request data backwards in time ...\n",
    "    while start < stop:\n",
    "        data = get_data_chunk(url, token, device[0], key, start, stop, 100000)\n",
    "        #print(data)\n",
    "        if key not in data:\n",
    "            break;\n",
    "        \n",
    "        #print(f\"{key}: Loaded {len(data[key])} points\")\n",
    "        t = pd.DataFrame.from_records(data[key])\n",
    "        #t['Timestamp'] = t['ts']\n",
    "        #pprint(t['ts'])\n",
    "        t['ts'] = (pd.to_datetime(t['ts'],unit='ms'))        \n",
    "        t.set_index('ts', inplace=True)\n",
    "        \n",
    "        t.rename(columns={'value': key}, inplace=True)\n",
    "        p = p._append(t)\n",
    "\n",
    "        # Update \"new\" stop time\n",
    "        stop = data[key][-1]['ts'] - 1\n",
    "    totalLength += len(p)\n",
    "    #print(f\"Total Length: {totalLength}\")\n",
    "    return p\n",
    "\n",
    "def outputCSV(devices):\n",
    "    global totalLength\n",
    "    final_df = pd.DataFrame()\n",
    "    for device in devices:\n",
    "        #print(f\"Downloading DEVICE: {device[0]} data\");\n",
    "        #print(device)\n",
    "        p = pd.DataFrame()\n",
    "        for key in keys:\n",
    "            #print(f\"info: Pulling {key}...\");\n",
    "            tempin = get_data(config['server'], token, device, key, startTS, endTS)            \n",
    "            if(len(tempin)>0):                \n",
    "                p = pd.concat([p,tempin], axis=1)\n",
    "        p['Entity Name'] = device[1]\n",
    "        p['dev_eui'] = device[2]    \n",
    "        p.reset_index(drop=False)\n",
    "        #p_new_index = p.assign(**{'Timestamp': p.index})        \n",
    "        if(len(p)):\n",
    "            final_df = pd.concat([final_df,p])\n",
    "        \n",
    "    # Create Time Strings\n",
    "    # Convert to nanoseconds for pandas.to_datetime\n",
    "    start_timestamp_ns = startTS * 1000000\n",
    "    end_timestamp_ns = endTS * 1000000\n",
    "    \n",
    "    # Convert timestamp to datetime object\n",
    "    start_dt = pd.to_datetime(start_timestamp_ns, unit='ns')\n",
    "    end_dt = pd.to_datetime(end_timestamp_ns, unit='ns')\n",
    "    \n",
    "    # Format datetime string as yyyy-mm-dd-HH-MM\n",
    "    start_formatted_string = start_dt.strftime('%Y-%m-%d-%H-%M')\n",
    "    end_formatted_string = end_dt.strftime('%Y-%m-%d-%H-%M')\n",
    "    # Select variables to export\n",
    "    df_order = [\"Entity Name\",\"data_soil_moisture4\",\"dev_eui\"]\n",
    "    final_df = final_df.reindex(columns=df_order)\n",
    "    final_df1 = final_df.sort_values(by='ts')\n",
    "    # final_df1['Entity Name'] = final_df1['Entity Name'].str.replace('ABE-DRAGINO-GROPOINT-CHERKHAUER-ACRE-','')\n",
    "    \n",
    "    # Get current time\n",
    "    now = datetime.datetime.now()\n",
    "    \n",
    "    # Format time string (hours and minutes)\n",
    "    formatted_time = now.strftime(\"%H-%M\")\n",
    "    # File saving directory\n",
    "    final_df1.to_csv(f\"./data-Layer4_{today}.csv\")\n",
    "    print(\"File Export Done.\")\n",
    "\n",
    "def getDeviceCredentialsByDeviceId(deviceID = 0):\n",
    "    url = config['server']+'/device/'+deviceID+'/credentials'\n",
    "    resp = requests.get(url,headers=TBheaders)\n",
    "    responseList = resp.json()\n",
    "    #pprint(responseList)\n",
    "    return responseList['credentialsID']\n",
    "\n",
    "def getDeviceServerAttributes(deviceID = 0):\n",
    "    if deviceID == 0:\n",
    "        while(deviceID == 0):\n",
    "            try:\n",
    "                deviceID = input(\"Enter device ID: \")\n",
    "            except:\n",
    "                print(\"Invalid DeviceID\")\n",
    "    url = config['server']+'/plugins/telemetry/DEVICE/'+deviceID+'/values/attributes'\n",
    "    #pprint(url)\n",
    "    #pprint(TBheaders)\n",
    "    xresp = requests.get(url,headers=TBheaders)\n",
    "    #pprint(xresp)\n",
    "    #pprint(resp.content())\n",
    "    #print(xresp.text())\n",
    "    responseList = xresp.json()\n",
    "    #pprint(responseList)\n",
    "    #return responseList['credentialsID']\n",
    "\n",
    "\n",
    "# ** getting token for the request                                                                                         **\n",
    "print(\"Server: \",config['server'])\n",
    "token = login(config['server'], config['username'], config['password']);\n",
    "# print(f\"Token: {token}\")\n",
    "TBheaders={ 'Accept': '*/*', 'X-Authorization': f\"Bearer {token}\" }\n",
    "\n",
    "\n",
    "\n",
    "# Create a datetime object representing the local date and time\n",
    "# Year, Month, Day, Hour, Minute\n",
    "today_dt = datetime.datetime.now()\n",
    "start = datetime.datetime.now()+ relativedelta(months=-2)\n",
    "\n",
    "start_dt = datetime.datetime(min(CED, SED).year, min(CED, SED).month, min(CED, SED).day, 18, 0)\n",
    "end_dt = datetime.datetime(today_dt.year, today_dt.month, today_dt.day, 6, 00)\n",
    "print (start_dt, end_dt)\n",
    "\n",
    "# Convert to a specific time zone (e.g., UTC)\n",
    "start_tz_utc = pytz.timezone(\"UTC\")\n",
    "start_dt_utc = start_tz_utc.localize(start_dt)\n",
    "end_tz_utc = pytz.timezone(\"UTC\")\n",
    "end_dt_utc = end_tz_utc.localize(end_dt)\n",
    "\n",
    "# Extract the Unix timestamp\n",
    "startTS = int(start_dt_utc.timestamp())*1000\n",
    "endTS = int(end_dt_utc.timestamp())*1000\n",
    "\n",
    "# Use for relative time frames\n",
    "#startTS = int((datetime.now() - timedelta(days=30)  - datetime(1970, 1, 1)).total_seconds() * 1000) # 30 days ago\n",
    "#endTS = int((datetime.datetime.utcnow() - datetime.datetime(1970, 1, 1)).total_seconds() * 1000) # now\n",
    "\n",
    "# print(startTS, endTS)\n",
    "\n",
    "\n",
    "\n",
    "# ** customer ID for the request                                                                                            **\n",
    "# getCustomerDevices(custID, textSearch=None):\n",
    "# 7576b020-ecae-11ec-b72b-5dd76ca52a2b = Cherkhauer Customer ID\n",
    "# ABE-DRAGINO-GROPOINT-CHERKHAUER = Devices with names beginning with \"ABE-DRAGINO-GROPOINT-CHERKHAUER\"\n",
    "devices = getCustomerDevices(\"7576b020-ecae-11ec-b72b-5dd76ca52a2b\",\"ABE-DRAGINO-GROPOINT-CHERKHAUER-ACRE\")\n",
    "# pprint(devices)\n",
    "\n",
    "totalLength = 0\n",
    "# keys to retrieve\n",
    "#keys = [\"data_TempC_SHT\",\"data_Hum_SHT\"]\n",
    "#keys = [\"data_ambient_temperature\",\"data_input1_frequency\",\"data_input1_frequency_to_moisture\",\"data_Input2_voltage\",\"data_Input2_voltage_to_temp\",\"data_light_intensity\",\"data_relative_humidity\"]\n",
    "keys = [\"data_soil_moisture4\"]\n",
    "\n",
    "outputCSV(devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b436c7e8-1647-49b9-9952-3bdac97b38c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "organazing the downloaded data\n",
    "    1. remove useless part from the station name\n",
    "    2. organize as dataframe form\n",
    "        2.1. frame into daily timesereis\n",
    "        2.2. group into field types\n",
    "    3. calculate the upperflux (UF) value following the equation\n",
    "\n",
    "'''\n",
    "\n",
    "# step 1. remove useless parts from the station name\n",
    "def read_L4df(filename):\n",
    "    print ('File name is ::',filename)\n",
    "    # open the file\n",
    "    raw_data = pd.read_csv(filename,delimiter=',', parse_dates=['ts'],\n",
    "                          dtype={'data_soil_moisture4':np.float64},\n",
    "                          na_values=['Invalid data']\n",
    "                          )\n",
    "    raw_columns = raw_data.columns.tolist()            \n",
    "    \n",
    "    # change the name of the Entity Name column\n",
    "    raw_data['Entity Name'] = raw_data['Entity Name'].str.replace('ABE-DRAGINO-GROPOINT-CHERKHAUER-ACRE-','')\n",
    "    stationlist = sorted(raw_data['Entity Name'].unique())\n",
    "\n",
    "    # filter the data by stationlist and hour (12am - 5am)\n",
    "    raw_data = raw_data[(raw_data['ts'].dt.hour >= 0) & (raw_data['ts'].dt.hour < 5)]\n",
    "    L4df = raw_data.pivot(index='ts', columns='Entity Name', values=['data_soil_moisture4'])\n",
    "    L4df.columns = L4df.columns.droplevel(0)\n",
    "    stationlist = L4df.columns\n",
    "            \n",
    "    # find diff values and resample in 'D' for each stations\n",
    "    # UFdf is empty dataframe for now\n",
    "    UFdf = pd.DataFrame(index=L4df.index.copy())\n",
    "    UFdf = UFdf.resample('D').sum()\n",
    "    for i in stationlist:\n",
    "        tempdf = L4df[[i]]        \n",
    "        tempdf = tempdf.dropna()\n",
    "        # get the hourly UF\n",
    "        tempdf = tempdf.diff()\n",
    "        # aggregate into daily\n",
    "        tempdf = tempdf.resample('D').sum()\n",
    "        UFdf = pd.concat([UFdf, tempdf], axis=1)\n",
    "    \n",
    "    return UFdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9ece634-2ca5-46c1-96ca-48ae4e281c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_UF(UFdf):\n",
    "    print(UFdf.columns.to_list())\n",
    "    # calculating mean values for each managements\n",
    "    # list of transmitters below\n",
    "    # make average to get UF for each managements\n",
    "    list_TRS = [CITRS, CFTRS, CRTRS, SITRS, SFTRS, SRTRS]\n",
    "    UFdf['CITRS'] = UFdf[CITRS].mean(axis=1)\n",
    "    UFdf['CFTRS'] = UFdf[CFTRS].mean(axis=1)\n",
    "    UFdf['CRTRS'] = UFdf[CRTRS].mean(axis=1)\n",
    "\n",
    "    UFdf['SITRS'] = UFdf[SITRS].mean(axis=1)\n",
    "    UFdf['SFTRS'] = UFdf[SFTRS].mean(axis=1)\n",
    "    UFdf['SRTRS'] = UFdf[SRTRS].mean(axis=1)\n",
    "\n",
    "    # extract UF for each plot managements\n",
    "    UFdf2 = UFdf[['CITRS', 'CFTRS', 'CRTRS', 'SITRS', 'SFTRS', 'SRTRS']]\n",
    "    # Unit conversion from % to inch. (6 = layer depth)\n",
    "    UFdf2 = UFdf2 * 0.01 * 6\n",
    "    UFdf2 = UFdf2.round(decimals=4)\n",
    "    \n",
    "    return UFdf, UFdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cedbeeb8-c445-415a-a97d-12df5a692949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File name is :: ./04_Soilmoisture_data/SM-Layer4_20240625.csv\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './04_Soilmoisture_data/SM-Layer4_20240625.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./04_Soilmoisture_data/SM-Layer4_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtoday\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m foutname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./CData_L4_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtoday\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 9\u001b[0m UFdf \u001b[38;5;241m=\u001b[39m \u001b[43mread_L4df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m UFdf, UFdf2 \u001b[38;5;241m=\u001b[39m get_UF(UFdf)\n",
      "Cell \u001b[0;32mIn[4], line 15\u001b[0m, in \u001b[0;36mread_L4df\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFile name is ::\u001b[39m\u001b[38;5;124m'\u001b[39m,filename)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# open the file\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m raw_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mts\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata_soil_moisture4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mInvalid data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                      \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m raw_columns \u001b[38;5;241m=\u001b[39m raw_data\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist()            \n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# change the name of the Entity Name column\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './04_Soilmoisture_data/SM-Layer4_20240625.csv'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "IMPLIMENTATION BLOCK\n",
    "'''\n",
    "\n",
    "destination = './'\n",
    "filename = f\"./04_Soilmoisture_data/SM-Layer4_{today}.csv\"\n",
    "foutname = f\"./CData_L4_{today}.csv\"\n",
    "\n",
    "UFdf = read_L4df(filename)\n",
    "UFdf, UFdf2 = get_UF(UFdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcaeb20-c08e-4a74-87b4-c798e91fa50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CITRS</th>\n",
       "      <th>CFTRS</th>\n",
       "      <th>CRTRS</th>\n",
       "      <th>SITRS</th>\n",
       "      <th>SFTRS</th>\n",
       "      <th>SRTRS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ts</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-05-26</th>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.567</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>0.066</td>\n",
       "      <td>-0.285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-27</th>\n",
       "      <td>0.126</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-28</th>\n",
       "      <td>0.012</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.096</td>\n",
       "      <td>-0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-29</th>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>-0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-30</th>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-31</th>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-01</th>\n",
       "      <td>0.063</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-02</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-03</th>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-04</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-05</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-06</th>\n",
       "      <td>0.150</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-07</th>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.171</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-08</th>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-09</th>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-10</th>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-11</th>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-12</th>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-13</th>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-14</th>\n",
       "      <td>0.084</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-15</th>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.465</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-16</th>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-17</th>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-18</th>\n",
       "      <td>-0.066</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-19</th>\n",
       "      <td>-0.066</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-20</th>\n",
       "      <td>-0.135</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-21</th>\n",
       "      <td>-0.156</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-22</th>\n",
       "      <td>-0.138</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-23</th>\n",
       "      <td>-0.105</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-24</th>\n",
       "      <td>0.042</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.096</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            CITRS  CFTRS  CRTRS  SITRS  SFTRS  SRTRS\n",
       "ts                                                  \n",
       "2024-05-26  0.003 -0.003 -0.567 -0.081  0.066 -0.285\n",
       "2024-05-27  0.126  0.054  0.018  0.099  0.153  0.144\n",
       "2024-05-28  0.012  0.006 -0.000  0.015  0.096 -0.105\n",
       "2024-05-29 -0.024 -0.033  0.000 -0.054 -0.057 -0.018\n",
       "2024-05-30 -0.012 -0.222 -0.048 -0.069 -0.102 -0.003\n",
       "2024-05-31  0.012 -0.018 -0.003  0.015  0.003  0.000\n",
       "2024-06-01  0.063  0.006  0.027  0.030  0.018  0.012\n",
       "2024-06-02  0.015  0.006  0.006  0.039  0.018  0.240\n",
       "2024-06-03 -0.015  0.015 -0.003  0.000  0.015 -0.237\n",
       "2024-06-04  0.000  0.000  0.000  0.027  0.015  0.009\n",
       "2024-06-05  0.000  0.000  0.000  0.036  0.027  0.018\n",
       "2024-06-06  0.150  0.273  0.138  0.036  0.039  0.036\n",
       "2024-06-07 -0.012 -0.171 -0.006  0.009 -0.006 -0.018\n",
       "2024-06-08 -0.039 -0.012 -0.021  0.012  0.003 -0.000\n",
       "2024-06-09  0.006 -0.003 -0.051  0.021  0.009  0.000\n",
       "2024-06-10  0.012 -0.006 -0.009  0.015  0.009  0.000\n",
       "2024-06-11  0.006  0.000  0.003  0.012  0.006  0.000\n",
       "2024-06-12 -0.006 -0.018 -0.006  0.006  0.003 -0.003\n",
       "2024-06-13  0.003 -0.021  0.009  0.024  0.021  0.009\n",
       "2024-06-14  0.084  0.270  0.555  0.048  0.039  0.279\n",
       "2024-06-15 -0.045 -0.186 -0.465  0.048  0.042 -0.231\n",
       "2024-06-16 -0.021 -0.087 -0.036 -0.024 -0.021  0.009\n",
       "2024-06-17 -0.048 -0.111 -0.012  0.012  0.015 -0.006\n",
       "2024-06-18 -0.066 -0.123 -0.003  0.018  0.027  0.012\n",
       "2024-06-19 -0.066 -0.060  0.009  0.015  0.021 -0.006\n",
       "2024-06-20 -0.135 -0.117 -0.048 -0.012 -0.012 -0.012\n",
       "2024-06-21 -0.156 -0.126 -0.087 -0.027  0.009 -0.006\n",
       "2024-06-22 -0.138 -0.096 -0.090 -0.045 -0.015 -0.006\n",
       "2024-06-23 -0.105 -0.060 -0.069 -0.057 -0.027 -0.009\n",
       "2024-06-24  0.042  0.042  0.096 -0.039  0.042 -0.021"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "positive value means there was increase of the moisture on that day compare to the previous day\n",
    "\"\"\"\n",
    "UFdf2.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77e7f30-f454-4aff-9c5a-68d66eb5fa86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
