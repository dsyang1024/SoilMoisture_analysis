{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1228ec27-35d2-436b-a4da-e3e5976e3cb5",
   "metadata": {},
   "source": [
    "# Testing the UF\n",
    "\n",
    "## Downloading the 4th layer data from the soil moisture DB (Thingsboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f92a6155-6264-48cf-b0d8-c18dce40e048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is : 20240624 // Week: 26\n",
      "Emergence week of corn : 18 // 8 weeks from now\n",
      "Emergence week of soybean : 20 // 6 weeks from now\n",
      "Root zone Growth rate for Corn:      0.4762 inch/day\n",
      "Root zone Growth rate for Soybean:   0.4762 inch/day\n",
      "Root Zone Depth for Corn:     24 inch\n",
      "Root Zone Depth for Soybean:  23.0476 inch\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "#  downloading the soil moisture data using the thingsboard API\n",
    "\n",
    "# Set up parameters for the simulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import datetime as dt\n",
    "import statistics as stats\n",
    "import os\n",
    "#*################ Global Parameters ################*#\n",
    "# transmitter info\n",
    "CTRS = ['0554','0556','0557','0558','0629','0630']  # Corn Transmitter IDs\n",
    "CITRS = ['0630','0557']\n",
    "CFTRS = ['0556','0629']\n",
    "CRTRS = ['0554','0558']\n",
    "STRS = ['0111','0112','0113','0114','0115','0116']   # Soybean Transmitter IDs\n",
    "SITRS = ['0112','0114']\n",
    "SFTRS = ['0113','0116']\n",
    "SRTRS = ['0111','0115']\n",
    "\n",
    "CED = pd.Timestamp(2024, 5, 1) # Corn Emergence Date\n",
    "SED = pd.Timestamp(2024, 5, 15) # Soybean Emergence Date\n",
    "\n",
    "CRZMD = 24 # Corn Root Zone Max Depth (in)\n",
    "CRZMDW = 7 # Week of Corn reaches Root Zone Max Depth (at the end of the week)\n",
    "CRZI = 4 # Corn Root Zone Initial Depth (in)\n",
    "CRZIW = 1 # Week of Corn reaches Root Zone Initial Depth\n",
    "\n",
    "SRZMD = 24 # Soybean Root Zone Max Depth (in)\n",
    "SRZMDW = 7 # Week of Soybean reaches Root Zone Max Depth (at the end of the week)\n",
    "SRZI = 4 # Soybean Root Zone Initial Depth (in)\n",
    "SRZIW = 1 # Week of Soybean reaches Root Zone Initial Depth\n",
    "\n",
    "\n",
    "#*################ Mendatory Parameters ################*#\n",
    "\n",
    "\n",
    "def get_periods(CED, SED):\n",
    "    # get today's date as string\n",
    "    from datetime import date\n",
    "    today = date.today().strftime(\"%Y%m%d\")\n",
    "\n",
    "    # Get today's date as datetime\n",
    "    TDY = pd.Timestamp.today()\n",
    "    TWK = TDY.isocalendar().week\n",
    "    print('Today is :', today, '// Week:', TWK)\n",
    "    # Corn Week From Emergence\n",
    "    Cweek = CED.isocalendar().week\n",
    "    CWPE = TWK - Cweek  # Corn Week From Emergence\n",
    "    print('Emergence week of corn :', Cweek, '//',CWPE, 'weeks from now')\n",
    "\n",
    "    # Soybean Week From Emergence\n",
    "    Sweek = SED.isocalendar().week\n",
    "    SWPE = TWK-Sweek  # Soybean Week From Emergence\n",
    "    print('Emergence week of soybean :', Sweek, '//',SWPE, 'weeks from now')\n",
    "\n",
    "    return today, TDY, CWPE, SWPE\n",
    "\n",
    "\n",
    "def cal_rz(TDY, CDE, SDE, CRZI, SRZI, CRZMDW, SRZMDW, CRZMD, SRZMD):\n",
    "    # this program is using linear group root growth rate\n",
    "    # get the root zone depth for corn and soybean\n",
    "    # get the days from emergence until the index date of dlydata (CDFE/SDFE)\n",
    "    CDFE = (TDY - CED).days\n",
    "    SDFE = (TDY - SED).days\n",
    "    \n",
    "    # root zone growth rate of corn (CRZGR/SRZGR) = CDFE*(CRZMD-CRZI)/(CRZMDW-1)*7 (inch/day)\n",
    "    CRZGR = (CRZMD-CRZI)/((CRZMDW-1)*7)\n",
    "    SRZGR = (SRZMD-SRZI)/((SRZMDW-1)*7)\n",
    "    print('Root zone Growth rate for Corn:     ', round(CRZGR,4), ('inch/day'))\n",
    "    print('Root zone Growth rate for Soybean:  ', round(SRZGR,4), ('inch/day'))\n",
    "\n",
    "    # calculate the root zone depth for corn and soybean\n",
    "    # if (CRZ/SRZ) is lower than CRZI/SRZI, then CRZ/SRZ is CRZI/SRZI\n",
    "    # if (CRZ/SRZ) is higher than CRZMD/SRZMD, then CRZ/SRZ is equal to CRZMD, SRZMD\n",
    "    \n",
    "    CRZ = CRZI + CDFE*CRZGR\n",
    "    CRZ = CRZMD if CRZ > CRZMD else CRZ\n",
    "    SRZ = SRZI + SDFE*SRZGR\n",
    "    SRZ = SRZMD if SRZ > SRZMD else SRZ\n",
    "    \n",
    "\n",
    "    # if CRZ/SRZ is below CRZI/SRZI, then CRZ/SRZ is 0\n",
    "    # this is because the date is before the emergence date\n",
    "    CRZ = round(CRZ if CRZ > CRZI else 0,4)\n",
    "    SRZ = round(SRZ if SRZ > SRZI else 0,4)\n",
    "\n",
    "    print('Root Zone Depth for Corn:    ', CRZ, ('inch'))    \n",
    "    print('Root Zone Depth for Soybean: ', SRZ, ('inch'))\n",
    "\n",
    "    return CRZ, SRZ\n",
    "\n",
    "today, TDY, CWPE, SWPE = get_periods(CED, SED)\n",
    "CRZ, SRZ = cal_rz(TDY, CWPE, SWPE, CRZI, SRZI, CRZMDW, SRZMDW, CRZMD, SRZMD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2fcfcc6e-7434-40e4-aaff-679609c87c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server:  https://things.iot.ag.purdue.edu:8080\n",
      "2024-05-01 18:00:00 2024-06-24 06:00:00\n",
      "File Export Done.\n"
     ]
    }
   ],
   "source": [
    "# // this part is download the data from the website for 2 month.\n",
    "import requests\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import datetime\n",
    "import pytz\n",
    "# import config  # I don't know what is this config but this is meaningless DK 2024-06-24\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "deviceList = []\n",
    "\n",
    "# ** set the configuration for the request                                                                                  **\n",
    "config = {\n",
    " 'username' : 'yang2309@purdue.edu', ### Insert your email address used by AgIT Thingsboard system\n",
    " 'password': 'dsya2002',  ### Insert your AgIT thingsboard password\n",
    " 'server' : 'https://things.iot.ag.purdue.edu:8080'\n",
    "}\n",
    "\n",
    "# ** defining the function to get the token for the request and setting the header for the request                          **\n",
    "def getCustomerDevices(custID, textSearch=None):\n",
    "    parameters = {        \n",
    "        'pageSize': 1000,\n",
    "        'page': 0,                \n",
    "    }\n",
    "    att_parms = {\n",
    "        'keys': 'dev_eui'\n",
    "    }\n",
    "    if(textSearch):\n",
    "        parameters.update({'textSearch': textSearch})\n",
    "    responseList = requests.get(f\"{config['server']}/api/customer/{custID}/devices\", headers=TBheaders,params= parameters).json()\n",
    "    #pprint(responseList)\n",
    "    list = []\n",
    "    for dev in responseList['data']:\n",
    "        #pprint(dev)\n",
    "        #print('------------------------------------------------------------------------------------------')\n",
    "        #'id': {'entityType': 'DEVICE', 'id': 'd49153a0-c868-11eb-95d8-09d06ef6a9a5'},\n",
    "        url = f\"{config['server']}/api/plugins/telemetry/DEVICE/{dev['id']['id']}/values/attributes\"\n",
    "        deviceResp = requests.get(url, headers=TBheaders,params= att_parms).json()\n",
    "        #print('------------------------------------------------------------------------------------------')\n",
    "        list.append([dev['id']['id'],dev['name'],deviceResp[0]['value']])\n",
    "    return list\n",
    "        \n",
    "\n",
    "def login(url, username, password):\n",
    "    # Log into ThingsBoard\n",
    "    return requests.post(f\"{url}/api/auth/login\", json={\n",
    "        \"username\": username,\n",
    "        \"password\": password\n",
    "    }).json()['token']\n",
    "\n",
    "def get_keys(device):\n",
    "    return requests.get(f\"{config['server']}/api/plugins/telemetry/DEVICE/{device}/keys/timeseries\",\n",
    "                 headers=TBheaders).json()\n",
    "def get_data_chunk(url, token, device, key, start, stop, limit):\n",
    "    #print([url, device, key, start, stop, limit])\n",
    "    return requests.get(f\"{url}/api/plugins/telemetry/DEVICE/{device}/values/timeseries\",\n",
    "             headers=TBheaders,\n",
    "            params= {\n",
    "                'keys': key,\n",
    "                'startTs': start,\n",
    "                'endTs': stop,\n",
    "                'limit': limit,\n",
    "                'agg': 'NONE'\n",
    "            }).json()\n",
    "\n",
    "def get_data(url, token, device, key, start, stop):\n",
    "    global totalLength\n",
    "    p = pd.DataFrame()\n",
    "    \n",
    "    # You have to request data backwards in time ...\n",
    "    while start < stop:\n",
    "        data = get_data_chunk(url, token, device[0], key, start, stop, 100000)\n",
    "        #print(data)\n",
    "        if key not in data:\n",
    "            break;\n",
    "        \n",
    "        #print(f\"{key}: Loaded {len(data[key])} points\")\n",
    "        t = pd.DataFrame.from_records(data[key])\n",
    "        #t['Timestamp'] = t['ts']\n",
    "        #pprint(t['ts'])\n",
    "        t['ts'] = (pd.to_datetime(t['ts'],unit='ms'))        \n",
    "        t.set_index('ts', inplace=True)\n",
    "        \n",
    "        t.rename(columns={'value': key}, inplace=True)\n",
    "        p = p._append(t)\n",
    "\n",
    "        # Update \"new\" stop time\n",
    "        stop = data[key][-1]['ts'] - 1\n",
    "    totalLength += len(p)\n",
    "    #print(f\"Total Length: {totalLength}\")\n",
    "    return p\n",
    "\n",
    "def outputCSV(devices):\n",
    "    global totalLength\n",
    "    final_df = pd.DataFrame()\n",
    "    for device in devices:\n",
    "        #print(f\"Downloading DEVICE: {device[0]} data\");\n",
    "        #print(device)\n",
    "        p = pd.DataFrame()\n",
    "        for key in keys:\n",
    "            #print(f\"info: Pulling {key}...\");\n",
    "            tempin = get_data(config['server'], token, device, key, startTS, endTS)            \n",
    "            if(len(tempin)>0):                \n",
    "                p = pd.concat([p,tempin], axis=1)\n",
    "        p['Entity Name'] = device[1]\n",
    "        p['dev_eui'] = device[2]    \n",
    "        p.reset_index(drop=False)\n",
    "        #p_new_index = p.assign(**{'Timestamp': p.index})        \n",
    "        if(len(p)):\n",
    "            final_df = pd.concat([final_df,p])\n",
    "        \n",
    "    # Create Time Strings\n",
    "    # Convert to nanoseconds for pandas.to_datetime\n",
    "    start_timestamp_ns = startTS * 1000000\n",
    "    end_timestamp_ns = endTS * 1000000\n",
    "    \n",
    "    # Convert timestamp to datetime object\n",
    "    start_dt = pd.to_datetime(start_timestamp_ns, unit='ns')\n",
    "    end_dt = pd.to_datetime(end_timestamp_ns, unit='ns')\n",
    "    \n",
    "    # Format datetime string as yyyy-mm-dd-HH-MM\n",
    "    start_formatted_string = start_dt.strftime('%Y-%m-%d-%H-%M')\n",
    "    end_formatted_string = end_dt.strftime('%Y-%m-%d-%H-%M')\n",
    "    # Select variables to export\n",
    "    df_order = [\"Entity Name\",\"data_soil_moisture4\",\"dev_eui\"]\n",
    "    final_df = final_df.reindex(columns=df_order)\n",
    "    final_df1 = final_df.sort_values(by='ts')\n",
    "    # final_df1['Entity Name'] = final_df1['Entity Name'].str.replace('ABE-DRAGINO-GROPOINT-CHERKHAUER-ACRE-','')\n",
    "    \n",
    "    # Get current time\n",
    "    now = datetime.datetime.now()\n",
    "    \n",
    "    # Format time string (hours and minutes)\n",
    "    formatted_time = now.strftime(\"%H-%M\")\n",
    "    # File saving directory\n",
    "    final_df1.to_csv(f\"./data-Layer4_{today}.csv\")\n",
    "    print(\"File Export Done.\")\n",
    "\n",
    "def getDeviceCredentialsByDeviceId(deviceID = 0):\n",
    "    url = config['server']+'/device/'+deviceID+'/credentials'\n",
    "    resp = requests.get(url,headers=TBheaders)\n",
    "    responseList = resp.json()\n",
    "    #pprint(responseList)\n",
    "    return responseList['credentialsID']\n",
    "\n",
    "def getDeviceServerAttributes(deviceID = 0):\n",
    "    if deviceID == 0:\n",
    "        while(deviceID == 0):\n",
    "            try:\n",
    "                deviceID = input(\"Enter device ID: \")\n",
    "            except:\n",
    "                print(\"Invalid DeviceID\")\n",
    "    url = config['server']+'/plugins/telemetry/DEVICE/'+deviceID+'/values/attributes'\n",
    "    #pprint(url)\n",
    "    #pprint(TBheaders)\n",
    "    xresp = requests.get(url,headers=TBheaders)\n",
    "    #pprint(xresp)\n",
    "    #pprint(resp.content())\n",
    "    #print(xresp.text())\n",
    "    responseList = xresp.json()\n",
    "    #pprint(responseList)\n",
    "    #return responseList['credentialsID']\n",
    "\n",
    "\n",
    "# ** getting token for the request                                                                                         **\n",
    "print(\"Server: \",config['server'])\n",
    "token = login(config['server'], config['username'], config['password']);\n",
    "# print(f\"Token: {token}\")\n",
    "TBheaders={ 'Accept': '*/*', 'X-Authorization': f\"Bearer {token}\" }\n",
    "\n",
    "\n",
    "\n",
    "# Create a datetime object representing the local date and time\n",
    "# Year, Month, Day, Hour, Minute\n",
    "today_dt = datetime.datetime.now()\n",
    "start = datetime.datetime.now()+ relativedelta(months=-2)\n",
    "\n",
    "start_dt = datetime.datetime(min(CED, SED).year, min(CED, SED).month, min(CED, SED).day, 18, 0)\n",
    "end_dt = datetime.datetime(today_dt.year, today_dt.month, today_dt.day, 6, 00)\n",
    "print (start_dt, end_dt)\n",
    "\n",
    "# Convert to a specific time zone (e.g., UTC)\n",
    "start_tz_utc = pytz.timezone(\"UTC\")\n",
    "start_dt_utc = start_tz_utc.localize(start_dt)\n",
    "end_tz_utc = pytz.timezone(\"UTC\")\n",
    "end_dt_utc = end_tz_utc.localize(end_dt)\n",
    "\n",
    "# Extract the Unix timestamp\n",
    "startTS = int(start_dt_utc.timestamp())*1000\n",
    "endTS = int(end_dt_utc.timestamp())*1000\n",
    "\n",
    "# Use for relative time frames\n",
    "#startTS = int((datetime.now() - timedelta(days=30)  - datetime(1970, 1, 1)).total_seconds() * 1000) # 30 days ago\n",
    "#endTS = int((datetime.datetime.utcnow() - datetime.datetime(1970, 1, 1)).total_seconds() * 1000) # now\n",
    "\n",
    "# print(startTS, endTS)\n",
    "\n",
    "\n",
    "\n",
    "# ** customer ID for the request                                                                                            **\n",
    "# getCustomerDevices(custID, textSearch=None):\n",
    "# 7576b020-ecae-11ec-b72b-5dd76ca52a2b = Cherkhauer Customer ID\n",
    "# ABE-DRAGINO-GROPOINT-CHERKHAUER = Devices with names beginning with \"ABE-DRAGINO-GROPOINT-CHERKHAUER\"\n",
    "devices = getCustomerDevices(\"7576b020-ecae-11ec-b72b-5dd76ca52a2b\",\"ABE-DRAGINO-GROPOINT-CHERKHAUER-ACRE\")\n",
    "# pprint(devices)\n",
    "\n",
    "totalLength = 0\n",
    "# keys to retrieve\n",
    "#keys = [\"data_TempC_SHT\",\"data_Hum_SHT\"]\n",
    "#keys = [\"data_ambient_temperature\",\"data_input1_frequency\",\"data_input1_frequency_to_moisture\",\"data_Input2_voltage\",\"data_Input2_voltage_to_temp\",\"data_light_intensity\",\"data_relative_humidity\"]\n",
    "keys = [\"data_soil_moisture4\"]\n",
    "\n",
    "outputCSV(devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b436c7e8-1647-49b9-9952-3bdac97b38c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "organazing the downloaded data\n",
    "    1. remove useless part from the station name\n",
    "    2. organize as dataframe form\n",
    "        2.1. frame into daily timesereis\n",
    "        2.2. group into field types\n",
    "    3. calculate the upperflux (UF) value following the equation\n",
    "\n",
    "'''\n",
    "\n",
    "# step 1. remove useless parts from the station name\n",
    "def readraw_data(destination, filename, foutname):\n",
    "    print ('File name is ::',filename)\n",
    "    # open the file\n",
    "    # TODO delimeter should be changed to ',' for the csv file.  ts <=> Timestamp.  delimiter=',' <=> delimiter=';'\n",
    "    raw_data = pd.read_csv(filename,delimiter=',', parse_dates=['ts'],\n",
    "                          dtype={'data_soil_moisture4':np.float64},\n",
    "                          na_values=['Invalid data']\n",
    "                          )\n",
    "    raw_columns = raw_data.columns.tolist()            \n",
    "    # raw_data.set_index(['ts'])\n",
    "    \n",
    "    # change the name of the Entity Name column\n",
    "    raw_data['Entity Name'] = raw_data['Entity Name'].str.replace('ABE-DRAGINO-GROPOINT-CHERKHAUER-ACRE-','')\n",
    "    stationlist = sorted(raw_data['Entity Name'].unique())\n",
    "    # print(stationlist)\n",
    "\n",
    "\n",
    "    # filter the data by stationlist and hour (12am - 5am)\n",
    "    raw_data = raw_data[(raw_data['ts'].dt.hour >= 0) & (raw_data['ts'].dt.hour < 5)]\n",
    "    # print(raw_data)\n",
    "    L4df = raw_data.pivot(index='ts', columns='Entity Name', values=['data_soil_moisture4'])\n",
    "    L4df.columns = L4df.columns.droplevel(0)\n",
    "    \n",
    "    # And resample into daily timestep\n",
    "    L4df = L4df.resample('D').mean()\n",
    "    # get the upward flux\n",
    "    L4df = L4df.diff()\n",
    "    # print(L4df)\n",
    "    return L4df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c9ece634-2ca5-46c1-96ca-48ae4e281c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UF_cal(L4df):\n",
    "    print(L4df.columns.to_list())\n",
    "    # calculating mean values for each managements\n",
    "    # list of transmitters below\n",
    "    # make average to get UF for each managements\n",
    "    list_TRS = [CITRS, CFTRS, CRTRS, SITRS, SCTRS, SRTRS]\n",
    "    L4df['CITRS'] = L4df[CITRS].mean(axis=1)\n",
    "    L4df['CFTRS'] = L4df[CFTRS].mean(axis=1)\n",
    "    L4df['CRTRS'] = L4df[CRTRS].mean(axis=1)\n",
    "\n",
    "    L4df['SITRS'] = L4df[SITRS].mean(axis=1)\n",
    "    L4df['SFTRS'] = L4df[SFTRS].mean(axis=1)\n",
    "    L4df['SRTRS'] = L4df[SRTRS].mean(axis=1)\n",
    "\n",
    "    # extract UF for each plot managements\n",
    "    UFdf = L4df[['CITRS', 'CFTRS', 'CRTRS', 'SITRS', 'SFTRS', 'SRTRS']]\n",
    "    \n",
    "    return L4df, UFdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "cedbeeb8-c445-415a-a97d-12df5a692949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File name is :: ./data-Layer4_20240624.csv\n",
      "['0111', '0112', '0113', '0114', '0115', '0116', '0554', '0556', '0557', '0558', '0629', '0630']\n"
     ]
    }
   ],
   "source": [
    "destination = './'\n",
    "filename = f\"./data-Layer4_{today}.csv\"\n",
    "foutname = f\"./CData_L4_{today}.csv\"\n",
    "\n",
    "L4df = readraw_data(destination, filename, foutname)\n",
    "L4df, UFdf = UF_cal(L4df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcaeb20-c08e-4a74-87b4-c798e91fa50e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
